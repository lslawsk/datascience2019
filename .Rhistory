# parse date range
start_date <- lubridate::myd(start, truncated = 2)
end_date <- myd(end, truncated = 2)
date_range <- seq(start_date, end_date, by = "months")
# use apply functions instead of for loops
# lapply(a, b) applies a function b to a sequence a and returns list of modified seq.
urls <- lapply(date_range, make_url, base_url = base_url)
# for loops can be easier for early development since they're more readable
for(u in urls) {
download.file(u, destfile = paste0(outdir,
str_sub(u, -11)))
}
}
## manual run ## test ##
# params
start = "6/21018"
end = "8/2018"
get_data(start, end)
# another way to just install
install.packages(c("lubridate", "dplyr", "stringr", "readr"))
install.packages(c("lubridate", "dplyr", "stringr", "readr"))
# another way to just install
# install.packages(c("lubridate", "dplyr", "stringr", "readr"))
get_data <- function(start, end,
base_url = "https://s3.amazonaws.com/biketown-tripdata-public/",
outdir = "data/biketown/") {
# takes start and end in mm/yyyy format, and tries to dl resulting files
# make url function only available within get_data
make_url <- function(date, base_url) {
url <- paste0(base_url,format(date, "%Y_%m"), ".csv")
return(url)
}
# parse date range
start_date <- lubridate::myd(start, truncated = 2)
end_date <- myd(end, truncated = 2)
date_range <- seq(start_date, end_date, by = "months")
# use apply functions instead of for loops
# lapply(a, b) applies a function b to a sequence a and returns list of modified seq.
urls <- lapply(date_range, make_url, base_url = base_url)
# for loops can be easier for early development since they're more readable
for(u in urls) {
download.file(u, destfile = paste0(outdir,
str_sub(u, -11)))
}
}
## manual run ## test ##
# params
start = "6/21018"
end = "8/2018"
get_data(start, end)
get_data <- function(start, end,
base_url = "https://s3.amazonaws.com/biketown-tripdata-public/",
outdir = "data/biketown/") {
# takes start and end in mm/yyyy format, and tries to dl resulting files
# make url function only available within get_data
make_url <- function(date, base_url) {
url <- paste0(base_url,format(date, "%Y_%m"), ".csv")
return(url)
}
# parse date range
start_date <- lubridate::myd(start, truncated = 2)
end_date <- lubridate::myd(end, truncated = 2)
date_range <- seq(start_date, end_date, by = "months")
# use apply functions instead of for loops
# lapply(a, b) applies a function b to a sequence a and returns list of modified seq.
urls <- lapply(date_range, make_url, base_url = base_url)
# for loops can be easier for early development since they're more readable
for(u in urls) {
download.file(u, destfile = paste0(outdir,
str_sub(u, -11)))
}
}
get_data(start, end)
get_data <- function(start, end,
base_url = "https://s3.amazonaws.com/biketown-tripdata-public/",
outdir = "data/biketown/") {
# takes start and end in mm/yyyy format, and tries to dl resulting files
# make url function only available within get_data
make_url <- function(date, base_url) {
url <- paste0(base_url,format(date, "%Y_%m"), ".csv")
return(url)
}
# parse date range
start_date <- lubridate::myd(start, truncated = 2)
end_date <- lubridate::myd(end, truncated = 2)
date_range <- seq(start_date, end_date, by = "months")
# use apply functions instead of for loops
# lapply(a, b) applies a function b to a sequence a and returns list of modified seq.
urls <- lapply(date_range, make_url, base_url = base_url)
# for loops can be easier for early development since they're more readable
for(u in urls) {
download.file(u, destfile = paste0(outdir,
str_sub(u, -11)))
}
}
start = "6/21018"
end = "8/2018"
get_data(start, end)
## manual run ## test ##
# params
start = "6/2018"
get_data(start, end)
pacman::p_load("stringr")
get_data <- function(start, end,
base_url = "https://s3.amazonaws.com/biketown-tripdata-public/",
outdir = "data/biketown/") {
# takes start and end in mm/yyyy format, and tries to dl resulting files
# make url function only available within get_data
make_url <- function(date, base_url) {
url <- paste0(base_url,format(date, "%Y_%m"), ".csv")
return(url)
}
# parse date range
start_date <- lubridate::myd(start, truncated = 2)
end_date <- lubridate::myd(end, truncated = 2)
date_range <- seq(start_date, end_date, by = "months")
# use apply functions instead of for loops
# lapply(a, b) applies a function b to a sequence a and returns list of modified seq.
urls <- lapply(date_range, make_url, base_url = base_url)
# for loops can be easier for early development since they're more readable
for(u in urls) {
download.file(u, destfile = paste0(outdir,
str_sub(u, -11)))
}
}
get_data(start, end)
# if no end date given, set to now to get all most recent
end <- ifelse(is.null(end), format(now(), "%m/%Y"),)
now()
now()
pacman::p_load("lubridate")
pacman::p_load("dplyr")
pacman::p_load("readr")
now()
# install.packages(c("lubridate", "dplyr", "stringr", "readr"))
get_data <- function(start = "7/2016", end = NULL,
base_url = "https://s3.amazonaws.com/biketown-tripdata-public/",
outdir = "data/biketown/") {
# takes start and end in mm/yyyy format, and tries to dl resulting files
# if no end date given, set to now to get all most recent
end <- ifelse(is.null(end), format(now(), "%m/%Y"), end)
# make url function only available within get_data
make_url <- function(date, base_url) {
url <- paste0(base_url,format(date, "%Y_%m"), ".csv")
return(url)
}
# parse date range
start_date <- lubridate::myd(start, truncated = 2)
end_date <- lubridate::myd(end, truncated = 2)
date_range <- seq(start_date, end_date, by = "months")
# use apply functions instead of for loops
# lapply(a, b) applies a function b to a sequence a and returns list of modified seq.
urls <- lapply(date_range, make_url, base_url = base_url)
# for loops can be easier for early development since they're more readable
for(u in urls) {
download.file(u, destfile = paste0(outdir,
str_sub(u, -11)))
}
}
get_data(start)
# if no end date given, set to now to get all most recent
end <- ifelse(is.null(end), format(lubridate::now(), "%m/%Y"), end)
get_data <- function(start = "7/2016", end = NULL,
base_url = "https://s3.amazonaws.com/biketown-tripdata-public/",
outdir = "data/biketown/") {
# takes start and end in mm/yyyy format, and tries to dl resulting files
# if no end date given, set to now to get all most recent
end <- ifelse(is.null(end), format(lubridate::now(), "%m/%Y"), end)
# make url function only available within get_data
make_url <- function(date, base_url) {
url <- paste0(base_url,format(date, "%Y_%m"), ".csv")
return(url)
}
# parse date range
start_date <- lubridate::myd(start, truncated = 2)
end_date <- lubridate::myd(end, truncated = 2)
date_range <- seq(start_date, end_date, by = "months")
# use apply functions instead of for loops
# lapply(a, b) applies a function b to a sequence a and returns list of modified seq.
urls <- lapply(date_range, make_url, base_url = base_url)
# for loops can be easier for early development since they're more readable
for(u in urls) {
download.file(u, destfile = paste0(outdir,
str_sub(u, -11)))
}
}
get_data(start)
## manual run ## test ##
# params
start = "11/2018"
get_data(start)
get_data(start)
source("code/fetch_biketown.R")
get_data(start = "06/2018", end = "08/2018")
get_data <- function(start = "7/2016", end = NULL,
base_url = "https://s3.amazonaws.com/biketown-tripdata-public/",
outdir = "data/biketown/") {
# takes start and end in mm/yyyy format, and tries to dl resulting files
# if no end date given, set to now to get all most recent
end <- ifelse(is.null(end), format(lubridate::now(), "%m/%Y"), end)
# make url function only available within get_data
make_url <- function(date, base_url) {
url <- paste0(base_url,format(date, "%Y_%m"), ".csv")
return(url)
}
# parse date range
start_date <- lubridate::myd(start, truncated = 2)
end_date <- lubridate::myd(end, truncated = 2)
date_range <- seq(start_date, end_date, by = "months")
# use apply functions instead of for loops
# lapply(a, b) applies a function b to a sequence a and returns list of modified seq.
urls <- lapply(date_range, make_url, base_url = base_url)
# for loops can be easier for early development since they're more readable
for(u in urls) {
download.file(u, destfile = paste0(outdir,
str_sub(u, -11)))
}
result <- lapply(urls, function(u) {
download.file(u, destfile = paste0(outdir, str_sub(u, -11)))
}) # enclose function within lapply
}
## manual run ## test ##
# params
start = "11/2018"
get_data(start)
# install.packages(c("lubridate", "dplyr", "stringr", "readr"))
get_data <- function(start = "7/2016", end = NULL,
base_url = "https://s3.amazonaws.com/biketown-tripdata-public/",
outdir = "data/biketown/") {
# takes start and end in mm/yyyy format, and tries to dl resulting files
# if no end date given, set to now to get all most recent
end <- ifelse(is.null(end), format(lubridate::now(), "%m/%Y"), end)
# make url function only available within get_data
make_url <- function(date, base_url) {
url <- paste0(base_url,format(date, "%Y_%m"), ".csv")
return(url)
}
# parse date range
start_date <- lubridate::myd(start, truncated = 2)
end_date <- lubridate::myd(end, truncated = 2)
date_range <- seq(start_date, end_date, by = "months")
# use apply functions instead of for loops
# lapply(a, b) applies a function b to a sequence a and returns list of modified seq.
urls <- lapply(date_range, make_url, base_url = base_url)
# for loops can be easier for early development since they're more readable
# for(u in urls) {
#   download.file(u, destfile = paste0(outdir,
#                                      str_sub(u, -11)))
# }
result <- lapply(urls, function(u) {
download.file(u, destfile = paste0(outdir, str_sub(u, -11)))
}) # enclose function within lapply
}
## manual run ## test ##
# params
start = "11/2018"
get_data(start)
?lapply()
get_data <- function(start = "7/2016", end = NULL,
base_url = "https://s3.amazonaws.com/biketown-tripdata-public/",
outdir = "data/biketown/") {
# takes start and end in mm/yyyy format, and tries to dl resulting files
# if no end date given, set to now to get all most recent
end <- ifelse(is.null(end), format(lubridate::now(), "%m/%Y"), end)
# make url function only available within get_data
make_url <- function(date, base_url) {
url <- paste0(base_url,format(date, "%Y_%m"), ".csv")
return(url)
}
# parse date range
start_date <- lubridate::myd(start, truncated = 2)
end_date <- lubridate::myd(end, truncated = 2)
date_range <- seq(start_date, end_date, by = "months")
# use apply functions instead of for loops
# lapply(a, b) applies a function b to a sequence a and returns list of modified seq.
# urls <- lapply(date_range, make_url, base_url = base_url)
# 3 different ways to do the same thing, 1) and 2) use urls from above
# 1) for loop over named list of urls; can be easier for early devel. since more readable
# for(u in urls) {
#   download.file(u, destfile = paste0(outdir,
#                                      str_sub(u, -11)))
# }
# 2) as apply with inline function
# result <- lapply(urls, function(u) {
#   download.file(u, destfile = paste0(outdir, str_sub(u, -11)))
# })
# 3) tidy piped function that combines creating urls to download files
urls <- lapply(date_range, make_url, base_url = base_url) %>%
lapply(function(u) {
download.file(u, destfile = paste0(outdir, str_sub(u, -11)))
})
}
get_data(start)
?lapply
get_data <- function(start = "7/2016", end = NULL,
base_url = "https://s3.amazonaws.com/biketown-tripdata-public/",
outdir = "data/biketown/") {
# takes start and end in mm/yyyy format, and tries to dl resulting files
# if no end date given, set to now to get all most recent
end <- ifelse(is.null(end), format(lubridate::now(), "%m/%Y"), end)
# make url function only available within get_data
make_url <- function(date, base_url) {
url <- paste0(base_url,format(date, "%Y_%m"), ".csv")
return(url)
}
# parse date range
start_date <- lubridate::myd(start, truncated = 2)
end_date <- lubridate::myd(end, truncated = 2)
date_range <- seq(start_date, end_date, by = "months")
# use apply functions instead of for loops
# lapply(a, b) applies a function b to a sequence a and returns list of modified seq.
# urls <- lapply(date_range, make_url, base_url = base_url)
# 3 different ways to do the same thing, 1) and 2) use urls from above
# 1) for loop over named list of urls; can be easier for early devel. since more readable
# for(u in urls) {
#   download.file(u, destfile = paste0(outdir,
#                                      str_sub(u, -11)))
# }
# 2) as apply with inline function
# result <- lapply(urls, function(u) {
#   download.file(u, destfile = paste0(outdir, str_sub(u, -11)))
# })
# 3) tidy piped function that combines creating urls to download files
lapply(date_range, make_url, base_url = base_url) %>%
lapply(function(u) {download.file(u, destfile = paste0(outdir,
str_sub(u, -11)))
})
}
get_data(start)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(lubridate)
library(ggplot2)
bike_1807 <- read.csv("data/biketown/2018_07.csv", stringsAsFactors = F)
str(bike_1807)
colnames(bike_1807)
mean_by_plan
mean_by_plan <- bike_1807 %>%
group_by(PaymentPlan) %>%
summarize(mean_mi = mean(Distance_Miles))
mean_by_plan
View(mean_by_plan)
View(mean_by_plan)
?ggplot
?ggplot
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(lubridate)
library(ggplot2)
install.packages("DataTable")
library(DataTable)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(lubridate)
library(ggplot2)
install.packages("DT")
library(DT)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(lubridate)
library(ggplot2)
install.packages("DT")
library(DT)
install.packages("DT")
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(lubridate)
library(ggplot2)
install.packages("DT")
library(DT)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(lubridate)
library(ggplot2)
bike_1807 <- read.csv("data/biketown/2018_07.csv", stringsAsFactors = F)
mean_by_plan <- bike_1807 %>%
group_by(PaymentPlan) %>%
summarize(mean_mi = mean(Distance_Miles))
plot1 <- ggplot(mean_by_plan, aes(PaymentPlan, mean_mi,
fill = PaymentPlan)) +
geom_bar(stat = "identity") +
labs(title = "Average Biketown Ride Distance by Payment Plan Type",
subtitle = "July 2018",
caption = "source: Biketown") +
xlab("Payment Plan") + ylab("Average Miles") +
theme_bw()
plot1
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(lubridate)
library(ggplot2)
install.packages("DT")
library(DT)
install.packages("DT")
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(lubridate)
library(ggplot2)
install.packages("DT")
library(DT)
str(bike_1807)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(lubridate)
library(ggplot2)
bike_1807 <- read.csv("data/biketown/2018_07.csv", stringsAsFactors = F)
mean_by_plan <- bike_1807 %>%
group_by(PaymentPlan) %>%
summarize(mean_mi = mean(Distance_Miles))
plot1 <- ggplot(mean_by_plan, aes(PaymentPlan, mean_mi,
fill = PaymentPlan)) +
geom_bar(stat = "identity") +
labs(title = "Average Biketown Ride Distance by Payment Plan Type",
subtitle = "July 2018",
caption = "source: Biketown") +
xlab("Payment Plan") + ylab("Average Miles") +
theme_bw()
plot1
mean_by <- bike_1807 %>%
group_by(PaymentPlan, MultipleRental) %>%
summarize(mean_mi2 = mean(Distance_Miles))
plot2 <- ggplot(mean_by, aes(PaymentPlan, mean_mi2,
fill = PaymentPlan)) +
geom_bar(stat = "identity") +
labs(title = "Average Biketown Ride Distance by Payment Plan Type",
subtitle = "July 2018",
caption = "source: Biketown") +
xlab("Payment Plan") + ylab("Average Miles") +
theme_bw()
plot2
bike_1807 <- read.csv("data/biketown/2018_07.csv", stringsAsFactors = F)
mean_by_plan <- bike_1807 %>%
group_by(PaymentPlan) %>%
summarize(mean_mi = mean(Distance_Miles))
plot1 <- ggplot(mean_by_plan, aes(PaymentPlan, mean_mi,
fill = PaymentPlan)) +
geom_bar(stat = "identity") +
labs(title = "Average Biketown Ride Distance by Payment Plan Type",
subtitle = "July 2018",
caption = "source: Biketown") +
xlab("Payment Plan") + ylab("Average Miles") +
theme_bw()
plot1
mean_by <- bike_1807 %>%
group_by(PaymentPlan, MultipleRental) %>%
summarize(mean_mi2 = mean(Distance_Miles))
plot2 <- ggplot(mean_by, aes(PaymentPlan, mean_mi2,
group_by(multipleRental),
fill = PaymentPlan)) +
geom_bar(stat = "identity") +
labs(title = "Average Biketown Ride Distance by Payment Plan Type",
subtitle = "July 2018",
caption = "source: Biketown") +
xlab("Payment Plan") + ylab("Average Miles") +
theme_bw()
plot2
bike_1807 <- read.csv("data/biketown/2018_07.csv", stringsAsFactors = F)
mean_by_plan <- bike_1807 %>%
group_by(PaymentPlan) %>%
summarize(mean_mi = mean(Distance_Miles))
plot1 <- ggplot(mean_by_plan, aes(PaymentPlan, mean_mi,
fill = PaymentPlan)) +
geom_bar(stat = "identity") +
labs(title = "Average Biketown Ride Distance by Payment Plan Type",
subtitle = "July 2018",
caption = "source: Biketown") +
xlab("Payment Plan") + ylab("Average Miles") +
theme_bw()
plot1
mean_by <- bike_1807 %>%
group_by(PaymentPlan, MultipleRental) %>%
summarize(mean_mi2 = mean(Distance_Miles))
plot2 <- ggplot(mean_by, aes(PaymentPlan, mean_mi2,
group_by(MultipleRental),
fill = PaymentPlan)) +
geom_bar(stat = "identity") +
labs(title = "Average Biketown Ride Distance by Payment Plan Type Breakout",
subtitle = "July 2018",
caption = "source: Biketown") +
xlab("Payment Plan") + ylab("Average Miles") +
theme_bw()
plot2
View(mean_by)
View(mean_by)
bike_1807 <- read.csv("data/biketown/2018_07.csv", stringsAsFactors = F)
mean_by_plan <- bike_1807 %>%
group_by(PaymentPlan) %>%
summarize(mean_mi = mean(Distance_Miles))
plot1 <- ggplot(mean_by_plan, aes(PaymentPlan, mean_mi,
fill = PaymentPlan)) +
geom_bar(stat = "identity") +
labs(title = "Average Biketown Ride Distance by Payment Plan Type",
subtitle = "July 2018",
caption = "source: Biketown") +
xlab("Payment Plan") + ylab("Average Miles") +
theme_bw()
plot1
mean_by <- bike_1807 %>%
group_by(PaymentPlan, MultipleRental) %>%
summarize(mean_mi2 = mean(Distance_Miles))
plot2 <- ggplot(mean_by, aes(PaymentPlan, mean_mi2,
group_by(MultipleRental),
fill = MultipleRental)) +
geom_bar(stat = "identity") +
labs(title = "Average Biketown Ride Distance by Payment Plan Type Breakout",
subtitle = "July 2018",
caption = "source: Biketown") +
xlab("Payment Plan") + ylab("Average Miles") +
theme_bw()
plot2
View(mean_by)
View(mean_by)
